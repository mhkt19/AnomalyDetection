# Anomaly Detection  
This project aims to develop a neural network-based classifier to detect anomalies (scratches) on metal surfaces using PyTorch. The dataset consists of images of metal surfaces categorized into two classes: `clean` and `faulty`.
## Requirements  
- Python 3.x
- PyTorch
- torchvision
- scikit-learn
- PIL (Python Imaging Library)  

## Dataset
The dataset used in this project is based on the NEU surface defect dataset and additional images generated by Girish4474. The dataset consists of images of metal surfaces, which are categorized into two folders:

1. Clean: Images of metal surfaces without any anomalies, generated from cleaned metal surfaces.

Examples of clean surface

![clean - (23)](https://github.com/mhkt19/AnomalyDetection/assets/3819181/ad65a0d3-a71a-495a-984e-10d68bcf9efa)![clean - (9)](https://github.com/mhkt19/AnomalyDetection/assets/3819181/550d911a-766c-4424-ad3d-0f6b376c91fa)![clean - (72)](https://github.com/mhkt19/AnomalyDetection/assets/3819181/16781171-d2d6-4f05-95be-23c2c998e09e)



2. Faulty: Images of metal surfaces with scratches or other anomalies, including types such as "scratches", "pitted surface", "crazing", "inclusion", "rolled-in", and "patches".

Examples of faulty surface

![crazing_1](https://github.com/mhkt19/AnomalyDetection/assets/3819181/1afd5323-f102-42b3-9408-2e963c320e1d) ![inclusion_21](https://github.com/mhkt19/AnomalyDetection/assets/3819181/512b6af3-e2cf-4d67-bc46-395bca3dc442)![patches_26](https://github.com/mhkt19/AnomalyDetection/assets/3819181/bacc670e-212b-48ad-8a30-b877127347a3)

![pitted_surface (13)](https://github.com/mhkt19/AnomalyDetection/assets/3819181/d4a774e0-0a34-41c8-897f-57edadc655b7)![scratches_10](https://github.com/mhkt19/AnomalyDetection/assets/3819181/79e48e9f-431e-4f64-8f2e-de7d49319a36)![rolled-in_scale_32](https://github.com/mhkt19/AnomalyDetection/assets/3819181/ebee0841-1e45-43c3-83c8-1cc3889248e2)



## Method:  
This project implements an anomaly detection algorithm for identifying defects in metal surfaces using a convolutional neural network (CNN). The neural network is built using the PyTorch library and utilizes the ResNet18 model pre-trained on the ImageNet dataset. The project includes several key features such as dynamic epoch determination with early stopping, dataset splitting into training and testing sets, data transformations, and calculation of various performance metrics.
### Code Explanation  
**Model Architecture:** The project uses the ResNet18 architecture, which is a well-known convolutional neural network pre-trained on the ImageNet dataset. The final layer of ResNet18 is replaced with a fully connected layer to accommodate binary classification (defective or non-defective).  
**Dynamic Epochs:** The training loop runs for a minimum of 5 epochs and a maximum of 15 epochs. However, if the model's performance on the validation set does not improve for a specified number of consecutive epochs (patience = 3), the training stops early to prevent overfitting.  
**Best Model Saving:** During training, the model with the best validation loss is saved. This ensures that the best performing model is used for evaluation.  
**Dataset Splitting:** The dataset is divided into training and testing sets with a specified ratio (70% training and 30% testing). Additionally, the training set is further split into training and validation sets (80% training and 20% validation) to monitor the model's performance during training.  
**Folder Structure:** For each run, timestamped directories are created to store the train, test, and misclassified images. This ensures that each run's results are stored separately.  
#### Performance Metrics  
##### Evaluation Metrics:  
After training, the model is evaluated on both the training and testing datasets. The following metrics are calculated:  
+ **Accuracy:** The ratio of correctly predicted instances to the total instances.  
+ **Confusion Matrix:** A table that describes the performance of the classification model by displaying the true positive, true negative, false positive, and false negative values.  
+ **Precision:** The ratio of true positive predictions to the sum of true positive and false positive predictions.  
+ **Recall:**  The ratio of true positive predictions to the sum of true positive and false negative predictions.   
+ **Duration:** The time taken to complete the training process.  
+ **Max Memory Usage:** The peak memory usage during the training process.  
##### Multiple Runs and Averaging: 
**Multiple Runs:** The entire training and evaluation process is repeated for a specified number of runs (10 by default). This helps in assessing the model's stability and consistency across different runs.  
**Averaging Statistics:** The average values of all calculated metrics across the runs are computed and stored in a separate file. This provides a comprehensive overview of the model's performance.  
## Result:
After training, evaluation metrics such as accuracy, precision, recall, and the confusion matrix are saved in metrics.txt. Since the training and testing data are selected randomly for each run, the results are not deterministic across multiple runs. However, the average statistics over 10 runs are listed below:  
**Average Train Accuracy:** 96.22%  
**Average Test Accuracy:** 95.43%  

## Contributing:
Feel free to contribute to this project by opening issues or submitting pull requests.

## License:
This project is licensed under the MIT License.
